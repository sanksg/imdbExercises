{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First import naive bayes and create a pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results Dict\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IMDB (Original Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers' from 'C:\\\\Users\\\\sankalpg\\\\Desktop\\\\Learning\\\\notebooks\\\\imdbExercise\\\\helpers.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n",
      "Original dataframe shape:  (100000, 4)\n",
      "Original DF columns: Index(['type', 'review', 'label', 'file'], dtype='object')\n",
      "Original Train/Test split: train    75000\n",
      "test     25000\n",
      "Name: type, dtype: int64\n",
      "Dropping the file column...\n",
      "Dropping the unlabeled rows and splitting into train/test...\n",
      "X_train, y_train, shapes: (25000,) (25000,)\n",
      "y_train counts: pos    12500\n",
      "neg    12500\n",
      "Name: label, dtype: int64\n",
      "X_test, y_test, shapes: (25000,) (25000,)\n",
      "y_test counts: pos    12500\n",
      "neg    12500\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "path = '../kaggleData/imdb-review-dataset/imdb_master.csv'\n",
    "x_train, y_train, x_test, y_test = helpers.load_imdb(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000    neg\n",
       "25001    neg\n",
       "25002    neg\n",
       "25003    neg\n",
       "25004    neg\n",
       "25005    neg\n",
       "25006    neg\n",
       "25007    neg\n",
       "25008    neg\n",
       "25009    neg\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countPipe1 = Pipeline([\n",
    "    ('countVect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'countVect__binary':[False, True],\n",
    "          'countVect__ngram_range':[(1,1), (1,3)],\n",
    "          'countVect__stop_words':[None, stopwords.words('english')]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = GridSearchCV(countPipe1, param_grid = params, n_jobs=4, scoring='accuracy', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed:  4.0min remaining:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countVect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preproc...nizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'countVect__binary': [False, True], 'countVect__ngram_range': [(1, 1), (1, 3)], 'countVect__stop_words': [None, ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'hims...shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'countVect__binary': True, 'countVect__ngram_range': (1, 3), 'countVect__stop_words': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.856 (+/-0.011) for {'countVect__binary': True, 'countVect__ngram_range': (1, 3), 'countVect__stop_words': None}\n",
      "0.841 (+/-0.005) for {'countVect__binary': False, 'countVect__ngram_range': (1, 3), 'countVect__stop_words': None}\n",
      "0.832 (+/-0.009) for {'countVect__binary': True, 'countVect__ngram_range': (1, 3), 'countVect__stop_words': True}\n",
      "0.808 (+/-0.010) for {'countVect__binary': False, 'countVect__ngram_range': (1, 3), 'countVect__stop_words': True}\n",
      "0.807 (+/-0.011) for {'countVect__binary': True, 'countVect__ngram_range': (1, 1), 'countVect__stop_words': True}\n",
      "0.802 (+/-0.013) for {'countVect__binary': True, 'countVect__ngram_range': (1, 1), 'countVect__stop_words': None}\n",
      "0.774 (+/-0.007) for {'countVect__binary': False, 'countVect__ngram_range': (1, 1), 'countVect__stop_words': True}\n",
      "0.771 (+/-0.009) for {'countVect__binary': False, 'countVect__ngram_range': (1, 1), 'countVect__stop_words': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helpers.print_gridSearch_report(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with CountVect and NB on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countPipe1 = Pipeline([\n",
    "    ('countVect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=Tru...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traintrain, X_Val, y_traintrain, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=33)\n",
    "logPipe3.fit(X_traintrain, y_traintrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy: %s\" % classifier.score(X_test, y_test))\n",
    "print(\"Log Loss: \" % log_loss(y_pred=classifier.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfPipe1 = Pipeline([\n",
    "    ('tfidfVect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'tfidfVect__max_df': [ 0.2, 0.5, 1.0],\n",
    "          'tfidfVect__binary':[False, True],\n",
    "          'tfidfVect__ngram_range':[(1,1), (1,3)],\n",
    "          'tfidfVect__stop_words':[None, stopwords.words('english')]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_cv = GridSearchCV(tfidfPipe1, param_grid = params, n_jobs=8, scoring='accuracy', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=8)]: Done  72 out of  72 | elapsed: 14.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  72 out of  72 | elapsed: 14.6min finished\n",
      "C:\\Users\\sankalpg\\AppData\\Local\\Continuum\\anaconda3\\envs\\mlpy\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidfVect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tru...rue,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'tfidfVect__max_df': [0.2, 0.5, 1.0], 'tfidfVect__binary': [False, True], 'tfidfVect__ngram_range': [(1, 1), (1, 3)], 'tfidfVect__stop_words': [None, ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', '...shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'tfidfVect__binary': True, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.868 (+/-0.008) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "0.866 (+/-0.010) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "0.865 (+/-0.011) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "0.856 (+/-0.005) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "0.854 (+/-0.004) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': True}\n",
      "0.854 (+/-0.004) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': True}\n",
      "0.854 (+/-0.004) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': True}\n",
      "0.853 (+/-0.007) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "0.852 (+/-0.008) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': None}\n",
      "0.833 (+/-0.006) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': True}\n",
      "0.832 (+/-0.007) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': True}\n",
      "0.831 (+/-0.008) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 3), 'tfidfVect__stop_words': True}\n",
      "0.819 (+/-0.005) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': True}\n",
      "0.819 (+/-0.005) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': True}\n",
      "0.818 (+/-0.008) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': None}\n",
      "0.817 (+/-0.005) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': True}\n",
      "0.817 (+/-0.005) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': None}\n",
      "0.817 (+/-0.009) for {'tfidfVect__binary': True, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': None}\n",
      "0.792 (+/-0.010) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': True}\n",
      "0.791 (+/-0.011) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.5, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': None}\n",
      "0.791 (+/-0.010) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': True}\n",
      "0.790 (+/-0.010) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 1.0, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': None}\n",
      "0.788 (+/-0.011) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': True}\n",
      "0.788 (+/-0.010) for {'tfidfVect__binary': False, 'tfidfVect__max_df': 0.2, 'tfidfVect__ngram_range': (1, 1), 'tfidfVect__stop_words': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helpers.print_gridSearch_report(tfidf_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize on the ngram range and min_df as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfPipe2 = Pipeline([\n",
    "    ('tfidfVect', TfidfVectorizer(max_df=0.2, binary=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params2 = {'tfidfVect__ngram_range':[(1,3), (1,5), (1,7)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_cv = RandomizedSearchCV(tfidfPipe2, param_grid = params2, n_jobs=-1, scoring='accuracy', verbose=5)\n",
    "tfidf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helpers.print_gridSearch_report(tfidf_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logPipe1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),`\n",
    "    ('clf', LogisticRegression(solver='sag')),\n",
    "])\n",
    "\n",
    "\n",
    "params = {'vectorizer__max_df': [ 0.2, 0.5, 1.0],\n",
    "          'vectorizer__binary':[False, True],\n",
    "          'vectorizer__ngram_range':[(1,1), (1,3)],\n",
    "          'clf__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 33.4min finished\n",
      "C:\\Users\\sankalpg\\AppData\\Local\\Continuum\\anaconda3\\envs\\mlpy\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ... penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'vectorizer__max_df': [0.2, 0.5, 1.0], 'vectorizer__binary': [False, True], 'vectorizer__ngram_range': [(1, 1), (1, 3)], 'clf__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv = RandomizedSearchCV(logPipe1, param_distributions = params, n_iter=20, n_jobs=-1, scoring='accuracy', verbose=5)\n",
    "log_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.883 (+/-0.008) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 100}\n",
      "0.882 (+/-0.006) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 10}\n",
      "0.881 (+/-0.006) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 100}\n",
      "0.877 (+/-0.008) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 1}\n",
      "0.877 (+/-0.008) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 100}\n",
      "0.873 (+/-0.012) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 1}\n",
      "0.873 (+/-0.011) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 10}\n",
      "0.869 (+/-0.013) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': False, 'clf__C': 1}\n",
      "0.867 (+/-0.011) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': False, 'clf__C': 0.01}\n",
      "0.865 (+/-0.012) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 0.1}\n",
      "0.864 (+/-0.010) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 0.1}\n",
      "0.862 (+/-0.006) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 0.01}\n",
      "0.858 (+/-0.017) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 0.1}\n",
      "0.857 (+/-0.018) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 10}\n",
      "0.853 (+/-0.015) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 1}\n",
      "0.851 (+/-0.012) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 0.1}\n",
      "0.847 (+/-0.017) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 100}\n",
      "0.846 (+/-0.004) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': False, 'clf__C': 0.001}\n",
      "0.841 (+/-0.014) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.2, 'vectorizer__binary': True, 'clf__C': 10}\n",
      "0.834 (+/-0.004) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 1.0, 'vectorizer__binary': False, 'clf__C': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helpers.print_gridSearch_report(log_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logPipe3 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1,3), max_df=0.5, binary=True)),\n",
    "    ('clf', LogisticRegression(C=100)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=Tru...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traintrain, X_Val, y_traintrain, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=33)\n",
    "logPipe3.fit(X_traintrain, y_traintrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy: %s\" % classifier.score(X_test, y_test))\n",
    "print(\"Log Loss: \" % log_loss(y_pred=classifier.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TFidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logPipe2 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='sag')),\n",
    "])\n",
    "\n",
    "\n",
    "params = {'vectorizer__max_df': [ 0.2, 0.5, 1.0],\n",
    "          'vectorizer__binary':[False, True],\n",
    "          'vectorizer__ngram_range':[(1,1), (1,3)],\n",
    "          'clf__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 24.7min finished\n",
      "C:\\Users\\sankalpg\\AppData\\Local\\Continuum\\anaconda3\\envs\\mlpy\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr... penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'vectorizer__max_df': [0.2, 0.5, 1.0], 'vectorizer__binary': [False, True], 'vectorizer__ngram_range': [(1, 1), (1, 3)], 'clf__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv = RandomizedSearchCV(logPipe2, param_distributions = params, n_iter=20, n_jobs=-1, scoring='accuracy', verbose=5)\n",
    "log_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.887 (+/-0.005) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 100}\n",
      "0.886 (+/-0.005) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': True, 'clf__C': 10}\n",
      "0.884 (+/-0.005) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 10}\n",
      "0.878 (+/-0.002) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': True, 'clf__C': 1}\n",
      "0.876 (+/-0.007) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 10}\n",
      "0.876 (+/-0.007) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 10}\n",
      "0.870 (+/-0.011) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 1}\n",
      "0.866 (+/-0.010) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.2, 'vectorizer__binary': True, 'clf__C': 1}\n",
      "0.865 (+/-0.003) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': True, 'clf__C': 0.1}\n",
      "0.863 (+/-0.004) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 1}\n",
      "0.863 (+/-0.014) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.5, 'vectorizer__binary': True, 'clf__C': 10}\n",
      "0.860 (+/-0.003) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.2, 'vectorizer__binary': True, 'clf__C': 0.01}\n",
      "0.849 (+/-0.016) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 100}\n",
      "0.846 (+/-0.009) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': True, 'clf__C': 0.001}\n",
      "0.845 (+/-0.017) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 1.0, 'vectorizer__binary': False, 'clf__C': 10}\n",
      "0.840 (+/-0.007) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 0.1}\n",
      "0.819 (+/-0.006) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.2, 'vectorizer__binary': False, 'clf__C': 0.001}\n",
      "0.815 (+/-0.016) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 0.001}\n",
      "0.805 (+/-0.008) for {'vectorizer__ngram_range': (1, 1), 'vectorizer__max_df': 0.5, 'vectorizer__binary': False, 'clf__C': 0.01}\n",
      "0.786 (+/-0.013) for {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 1.0, 'vectorizer__binary': False, 'clf__C': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helpers.print_gridSearch_report(log_cv, score='log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize ngrams a bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logPipe3 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "\n",
    "params = {'vectorizer__max_df': ss.uniform(0.1, 0.9),\n",
    "          'vectorizer__binary':[True],\n",
    "          'vectorizer__ngram_range':[(1,3), (1,5)],\n",
    "          'clf__C': [100, 1000]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.0min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  4.6min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  4.6min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  4.6min\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  6.6min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  9.0min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  9.1min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  9.1min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 11.0min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 13.2min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 13.4min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 15.2min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 17.9min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 18.0min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 18.0min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 19.8min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 22.6min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 22.6min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 22.7min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 22.8min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 24.6min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  30 | elapsed: 24.7min remaining:  6.2min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16666,), dtype=int32).\n",
      "Pickling array (shape=(8334,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  30 | elapsed: 26.9min remaining:  5.4min\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(25000,), dtype=object).\n",
      "Pickling array (shape=(25000,), dtype=int64).\n",
      "Pickling array (shape=(16668,), dtype=int32).\n",
      "Pickling array (shape=(8332,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  30 | elapsed: 26.9min remaining:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 26.9min remaining:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  30 | elapsed: 28.6min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 28.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 28.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'vectorizer__max_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002CB214E96D8>, 'vectorizer__binary': [True], 'vectorizer__ngram_range': [(1, 3), (1, 5)], 'clf__C': [100, 1000]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_log_loss', verbose=100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv = RandomizedSearchCV(logPipe3, param_distributions=params, n_iter=10, n_jobs=-1, scoring='neg_log_loss', verbose=100)\n",
    "log_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'clf__C': 100, 'vectorizer__binary': True, 'vectorizer__max_df': 0.6775468592953785, 'vectorizer__ngram_range': (1, 3)}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.269 (+/-0.013) for {'clf__C': 100, 'vectorizer__binary': True, 'vectorizer__max_df': 0.6775468592953785, 'vectorizer__ngram_range': (1, 3)}\n",
      "-0.280 (+/-0.006) for {'clf__C': 100, 'vectorizer__binary': True, 'vectorizer__max_df': 0.41501032289852635, 'vectorizer__ngram_range': (1, 5)}\n",
      "-0.284 (+/-0.003) for {'clf__C': 100, 'vectorizer__binary': True, 'vectorizer__max_df': 0.614813958993365, 'vectorizer__ngram_range': (1, 5)}\n",
      "-0.284 (+/-0.003) for {'clf__C': 100, 'vectorizer__binary': True, 'vectorizer__max_df': 0.71537138175446779, 'vectorizer__ngram_range': (1, 5)}\n",
      "-0.285 (+/-0.003) for {'clf__C': 100, 'vectorizer__binary': True, 'vectorizer__max_df': 0.85923999601435741, 'vectorizer__ngram_range': (1, 5)}\n",
      "-0.289 (+/-0.018) for {'clf__C': 1000, 'vectorizer__binary': True, 'vectorizer__max_df': 0.84459407569077705, 'vectorizer__ngram_range': (1, 3)}\n",
      "-0.289 (+/-0.018) for {'clf__C': 1000, 'vectorizer__binary': True, 'vectorizer__max_df': 0.58051432605240694, 'vectorizer__ngram_range': (1, 3)}\n",
      "-0.295 (+/-0.014) for {'clf__C': 1000, 'vectorizer__binary': True, 'vectorizer__max_df': 0.2122323659168078, 'vectorizer__ngram_range': (1, 5)}\n",
      "-0.303 (+/-0.009) for {'clf__C': 1000, 'vectorizer__binary': True, 'vectorizer__max_df': 0.39565551405084187, 'vectorizer__ngram_range': (1, 5)}\n",
      "-0.308 (+/-0.005) for {'clf__C': 1000, 'vectorizer__binary': True, 'vectorizer__max_df': 0.63678948306244421, 'vectorizer__ngram_range': (1, 5)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helpers.print_gridSearch_report(log_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logPipe3 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1,3), max_df=0.5, binary=True)),\n",
    "    ('clf', LogisticRegression(C=100)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=Tru...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traintrain, X_Val, y_traintrain, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=33)\n",
    "logPipe3.fit(X_traintrain, y_traintrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy: %s\" % classifier.score(X_test, y_test))\n",
    "print(\"Log Loss: \" % log_loss(y_pred=classifier.predict(X_test), y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
